[Data]

; all images should be placed under this dir
image_source_dir = ./IU-XRay/images/
data_dir = ./IU-XRay/

training_set_csv = training_set.csv
testing_set_csv = testing_set.csv
all_data_csv = all_data.csv

[Captioning_Model]

class_names = Caption
buffer_size = 1000
embedding_dim = 400
units = 1024
features_shape = 1024
attention_features_shape = 49
max_sequence_length = 170
tokenizer_vocab_size = 1001

[Captioning_Model_Train]
epochs = 100
batch_size = 64
continue_from_last_ckpt = true
ckpt_path = ./checkpoints/best_checkpoints/big
[Captioning_Model_Inference]
batch_size = 1
output_images_folder = test_captions_big
[Chexnet_Default]
; working directory, one working directory can only have one running job at a time
weights_dir = ./pretrained_models

; base model name
; one of: VGG16, VGG19, DenseNet121, ResNet50, InceptionV3, InceptionResNetV2,
; NASNetMobile, NASNetLarge
base_model_name = DenseNet121

; class names, you should not modify this
chexnet_class_names = Atelectasis,Cardiomegaly,Effusion,Infiltration,Mass,Nodule,Pneumonia,Pneumothorax,Consolidation,Edema,Emphysema,Fibrosis,Pleural_Thickening,Hernia

; target width/height of the input image (resized)
image_dimension = 224

[Chexnet_Train]
; use base model weights or not. If true, imagenet pretrained weights will be used.
use_base_model_weights = true

; if true, load trained model weights saved in output_dir
; this is typically used for resuming your previous training tasks
; so the use_split_dataset will be automatically set to false
; also, make sure you use the reasonable initial_learning_rate
use_trained_model_weights = false
; if true, use best weights, else use last weights
use_best_weights = false

; note that the best weighting will be saved as best_weights.h5
output_weights_name = chexnet_densenet121_weights.h5

; basic training parameters
epochs = 100
batch_size = 32

; learning rate options
initial_learning_rate = 0.001

; worker number of the image generators
generator_workers = 8



; patience parameter used for ReduceLROnPlateau callback
; If val_loss doesn't decrease for x epochs, learning rate will be reduced by factor of 10.
patience_reduce_lr = 1

; minimun learning rate
min_lr = 1e-8

; this variable controlls the class_weight ratio between 0 and 1
; higher value means higher weighting of positive samples
positive_weights_multiply = 1

; path of the folder that contains train.csv|dev.csv|test.csv
dataset_csv_dir = ./data/default_split

; print model summary
show_model_summary = true

[Chexnet_Inference]
batch_size = 64
test_generator_random_state = 1
; if true, use best_weights.h5, else use weights.h5
use_best_weights = true
weights_name = chexnet_densenet121_weights.h5
; use base model weights or not. If true, imagenet pretrained weights will be used.
use_base_model_weights = false
[CAM]
bbox_list_file = ./data/BBox_List_2017.csv
use_best_weights = true
